<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="YoojinKim">
<meta name="dcterms.date" content="2022-07-13">
<meta name="description" content="Node Embeddings">

<title>CS224W-KOR Blog - Lecture 3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS224W-KOR Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">Study Group</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/CS224W-KOR"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Lecture 3</h1>
                  <div>
        <div class="description">
          Node Embeddings
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LEC03</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>YoojinKim </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 13, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#node-embedding" id="toc-node-embedding" class="nav-link active" data-scroll-target="#node-embedding">3.1 Node Embedding</a>
  <ul class="collapse">
  <li><a href="#graph-representation-learning" id="toc-graph-representation-learning" class="nav-link" data-scroll-target="#graph-representation-learning">Graph Representation Learning</a></li>
  <li><a href="#why-embedding" id="toc-why-embedding" class="nav-link" data-scroll-target="#why-embedding">Why Embedding?</a></li>
  <li><a href="#example-node-embedding" id="toc-example-node-embedding" class="nav-link" data-scroll-target="#example-node-embedding">Example Node Embedding</a></li>
  <li><a href="#node-embeddings-encoder-and-decoder" id="toc-node-embeddings-encoder-and-decoder" class="nav-link" data-scroll-target="#node-embeddings-encoder-and-decoder">Node Embeddings: Encoder and Decoder</a></li>
  <li><a href="#learning-node-embeddings" id="toc-learning-node-embeddings" class="nav-link" data-scroll-target="#learning-node-embeddings">Learning Node Embeddings</a></li>
  <li><a href="#shallow-encoding" id="toc-shallow-encoding" class="nav-link" data-scroll-target="#shallow-encoding">Shallow Encoding</a></li>
  <li><a href="#note-on-node-embeddings" id="toc-note-on-node-embeddings" class="nav-link" data-scroll-target="#note-on-node-embeddings">Note on Node Embeddings</a></li>
  </ul></li>
  <li><a href="#random-walk-approaches-for-node-embeddings" id="toc-random-walk-approaches-for-node-embeddings" class="nav-link" data-scroll-target="#random-walk-approaches-for-node-embeddings">3.2 Random Walk Approaches for Node embeddings</a>
  <ul class="collapse">
  <li><a href="#why-random-walks" id="toc-why-random-walks" class="nav-link" data-scroll-target="#why-random-walks">Why Random Walks?</a></li>
  <li><a href="#unsupervised-feature-learning" id="toc-unsupervised-feature-learning" class="nav-link" data-scroll-target="#unsupervised-feature-learning">Unsupervised Feature Learning</a></li>
  <li><a href="#feature-learning-as-optimization" id="toc-feature-learning-as-optimization" class="nav-link" data-scroll-target="#feature-learning-as-optimization">Feature Learning as Optimization</a></li>
  <li><a href="#random-walk-optimization" id="toc-random-walk-optimization" class="nav-link" data-scroll-target="#random-walk-optimization">Random Walk Optimization</a></li>
  <li><a href="#how-should-we-randomly-walk" id="toc-how-should-we-randomly-walk" class="nav-link" data-scroll-target="#how-should-we-randomly-walk">How should we randomly walk?</a></li>
  <li><a href="#node2vec-biased-walks" id="toc-node2vec-biased-walks" class="nav-link" data-scroll-target="#node2vec-biased-walks">node2vec : Biased Walks</a></li>
  <li><a href="#interpolating-bfs-and-dfs" id="toc-interpolating-bfs-and-dfs" class="nav-link" data-scroll-target="#interpolating-bfs-and-dfs">Interpolating BFS and DFS</a></li>
  <li><a href="#biased-2nd-order-random-walks" id="toc-biased-2nd-order-random-walks" class="nav-link" data-scroll-target="#biased-2nd-order-random-walks">Biased 2nd-order random walks</a></li>
  <li><a href="#node2vec-algorithm" id="toc-node2vec-algorithm" class="nav-link" data-scroll-target="#node2vec-algorithm">node2vec algorithm</a></li>
  </ul></li>
  <li><a href="#embedding-entire-graphs" id="toc-embedding-entire-graphs" class="nav-link" data-scroll-target="#embedding-entire-graphs">3.3 Embedding Entire Graphs</a>
  <ul class="collapse">
  <li><a href="#simple-use-of-anonymous-walks" id="toc-simple-use-of-anonymous-walks" class="nav-link" data-scroll-target="#simple-use-of-anonymous-walks">Simple Use of Anonymous Walks</a></li>
  <li><a href="#sampling-anonymous-walks" id="toc-sampling-anonymous-walks" class="nav-link" data-scroll-target="#sampling-anonymous-walks">Sampling Anonymous Walks</a></li>
  <li><a href="#new-idea-learn-walk-embeddings" id="toc-new-idea-learn-walk-embeddings" class="nav-link" data-scroll-target="#new-idea-learn-walk-embeddings">New idea : Learn Walk Embeddings</a></li>
  <li><a href="#summary-of-graph-embedding" id="toc-summary-of-graph-embedding" class="nav-link" data-scroll-target="#summary-of-graph-embedding">Summary of Graph embedding</a></li>
  <li><a href="#how-to-use-embeddings" id="toc-how-to-use-embeddings" class="nav-link" data-scroll-target="#how-to-use-embeddings">How to Use Embeddings</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="node-embedding" class="level2">
<h2 class="anchored" data-anchor-id="node-embedding">3.1 Node Embedding</h2>
<section id="graph-representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="graph-representation-learning">Graph Representation Learning</h3>
<p><strong>representation learning ëª©ì </strong>ì€ feature engineeringì„ í†µí•´ ì§ì ‘ nodeì˜ featureë¥¼ ì§€ì •í•˜ëŠ” ëŒ€ì‹ , <strong>featureë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµ</strong>í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>
<p>ê·¸ë¦¼ì—ì„œì™€ ê°™ì´, representation learningì„ ê±°ì³ node uë¥¼ dì°¨ì› vectorë¡œ í‘œí˜„í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë•Œ, featureë¥¼ í‘œí˜„í•˜ëŠ” vectorë¥¼ <strong>â€˜feature representationâ€™ í˜¹ì€ â€˜embeddingâ€™</strong>ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ì´ vectorëŠ” nodeì˜ íŠ¹ì§•ì„ ì˜ ë‹´ì•„ë‚´ì•¼ í•˜ë©°, ê·¸ë˜í”„ì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì˜ ì˜ë¯¸ë„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled.png" class="img-fluid"></p>
</section>
<section id="why-embedding" class="level3">
<h3 class="anchored" data-anchor-id="why-embedding">Why Embedding?</h3>
<p><strong>embedding spaceë‚´ì— í‘œí˜„ëœ nodeë“¤ì€ ìœ ì‚¬ì„±(similarity) ê°€ì§ˆìˆ˜ë¡ ë¹„ìŠ·í•œ embeddingì„ ê°€ì§„ë‹¤</strong>ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í‘œí˜„ëœ nodeë“¤ì€ í›„ì† ì‘ì—…ì¸ ì˜ˆì¸¡ task (node classification, link prediction, graph classification ë“±)ì— íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.</p>
</section>
<section id="example-node-embedding" class="level3">
<h3 class="anchored" data-anchor-id="example-node-embedding">Example Node Embedding</h3>
<p>DeepWalk ì˜ ì—°êµ¬ë¡œ, Zacharyâ€™s Karate Club networkë¥¼ 2ì°¨ì› vectorì˜ featureë¡œ í‘œí˜„í–ˆìŠµë‹ˆë‹¤. <strong>ê°™ì€ ìƒ‰ìƒì„ ê°€ì§„ nodeë¼ë¦¬ ë¹„ìŠ·í•œ vector ê°’ì„ ê°–ëŠ” ê²ƒ</strong>ì„ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ embedding ì‘ì—…ì´ ê½¤ ì„±ê³µì ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 1.png" class="img-fluid"></p>
</section>
<section id="node-embeddings-encoder-and-decoder" class="level3">
<h3 class="anchored" data-anchor-id="node-embeddings-encoder-and-decoder">Node Embeddings: Encoder and Decoder</h3>
<p>ìš°ì„  ê°„ë‹¨í•œ ê·¸ë˜í”„ì—ì„œ ì‹œì‘í•´ë´…ì‹œë‹¤!</p>
<p>featureëŠ” ì—†ê³ , ì—°ê²° ê´€ê³„ë§Œ(adjacency matrix)ë§Œ ì¡´ì¬í•˜ëŠ” undirected ê·¸ë˜í”„ê°€ ìˆë‹¤ê³  í•©ì‹œë‹¤. ì´ë•Œ embedding ëª©í‘œëŠ” <strong>embeddingí›„ì˜ embedding spaceì—ì„œì˜ ê° nodeë¼ë¦¬ì˜ ìœ ì‚¬ì„±(similarity)ê³¼ ê·¸ë˜í”„ìƒì—ì„œì˜ ìœ ì‚¬ì„±</strong>ì´ ë¹„ìŠ·í•´ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤. <strong>embedding spaceì—ì„œì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•  ë•ŒëŠ” vectorê°„ì˜ dot product ì—°ì‚°ì„ ìˆ˜í–‰</strong>í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. <strong>dot product</strong>ì€ <span class="math inline">\(a \cdot b = |a||b|cos\theta\)</span> ì´ë¯€ë¡œ, <strong>ë‘ vectorê°„ì˜ ê°ë„ê°€ ì‘ì„ìˆ˜ë¡(=ê°€ê¹Œì›€, ë¹„ìŠ·í•¨), í° ê°’</strong>ì„ ê°–ê²Œ ë©ë‹ˆë‹¤. ì ì´ì œ, embedding spaceì—ì„œì˜ ìœ ì‚¬ì„±ì€ ì¸¡ì •í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìœ¼ë¯€ë¡œ, <strong>ê·¸ë˜í”„ìƒì—ì„œì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” similarity functionì„ ì •ì˜</strong>í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><strong>Goal :</strong> <span class="math inline">\(\red {similarity(u,v)} \;\approx\; \green{z^T_v z_u}\)</span></p>
</blockquote>
<p><img src="../images/lec03/Untitled 2.png" class="img-fluid"></p>
</section>
<section id="learning-node-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="learning-node-embeddings">Learning Node Embeddings</h3>
<p><strong>1) Encoderë¥¼ í†µí•´ nodeë¥¼ embeddingê°’ìœ¼ë¡œ ë³€í™˜</strong>í•©ë‹ˆë‹¤. Encoder : <span class="math inline">\(ENC(v) = z_v\)</span>, <span class="math inline">\(z_v : d\)</span>-dimensional embedding ì´ë•Œ, embedding ì°¨ì›ìœ¼ë¡œ ë³´í†µ 64~1000ì„ ì±„íƒí•©ë‹ˆë‹¤.</p>
<p><strong>2)</strong> <strong>ê·¸ë˜í”„ ìƒì—ì„œì˜ ë…¸ë“œ ê°„ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•  similarity functionì„ ì •ì˜</strong>í•©ë‹ˆë‹¤.</p>
<p><strong>3) DecoderëŠ” embeddingê°’ë“¤ ê°„ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •</strong>í•©ë‹ˆë‹¤. â†’ similarity score Decoder : <span class="math inline">\(DEC(z^T_vz_u)\)</span></p>
<p><strong>4) <span class="math inline">\(\red {similarity(u,v)} \;\approx\; \green{z^T_v z_u}\)</span>ê°€ ë  ìˆ˜ ìˆë„ë¡, Encoderì˜ parameterë“¤ì„ ìµœì í™”</strong> í•©ë‹ˆë‹¤.</p>
</section>
<section id="shallow-encoding" class="level3">
<h3 class="anchored" data-anchor-id="shallow-encoding">Shallow Encoding</h3>
<p>ê°€ì¥ ê°„ë‹¨í•œ encoderëŠ” ë‹¨ìˆœí•œ <strong>embedding-lookup(â†’ì¡°íšŒ)</strong>ì…ë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><span class="math inline">\(ENC(v) = z_v= Z \cdot v\)</span> , <span class="math inline">\(Z\in\R^{d*|v|}\)</span>, <span class="math inline">\(v\in I^{|v|}\)</span></p>
</blockquote>
<p>ì—¬ê¸°ì„œ <span class="math inline">\(**Z\)</span>ëŠ” ëª¨ë“  nodeì˜ embeddingì„ í¬í•¨í•˜ëŠ” matrixë¡œ ê° columnì´ í•˜ë‚˜ì˜ node embeddingì„ ì˜ë¯¸<strong>í•©ë‹ˆë‹¤. <span class="math inline">\(v\)</span>ëŠ” indicator vectorë¡œ, í˜„ì¬ í‘œí˜„í•  nodeë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” 0ì¸ vectorì…ë‹ˆë‹¤. </strong>ì´ë•Œì˜ ëª©í‘œëŠ” matrix <span class="math inline">\(Z\)</span>ë¥¼ ìµœì í™”<strong>í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ë°©ë²•ì„ ì´ìš©í•œ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ì€ </strong>DeepWalkì™€ node2vec**ì´ ìˆìŠµë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 3.png" class="img-fluid"></p>
<p>í•˜ì§€ë§Œ ì´ë•Œì˜ <strong>ë¬¸ì œì ì€ ìµœì í™”í•´ì•¼ í•  embedding matrix <span class="math inline">\(Z\)</span>ì˜ parameterìˆ˜ê°€ ë§¤ìš° ì»¤ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì </strong>ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 10ì–µ ê°œ nodeë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„ì— ëŒ€í•´ì„œ ìµœì í™” í•´ì•¼ í•  parameterëŠ” (10ì–µ * embedding dimension)ê°œ ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í•´ë‹¹ ë°©ë²•ì€ ë‹¨ìˆœ lookup ìœ¼ë¡œ ë§¤ìš° ê°„ë‹¨í•  ìˆ˜ ìˆì§€ë§Œ, í™•ì¥ ê°€ëŠ¥ì„±ì´ ì‘ìŠµë‹ˆë‹¤.(= low scalability)</p>
<p>(vs.&nbsp;deep encoder(GNNs)ëŠ” 6ì¥ì—ì„œë¶€í„° ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤ğŸ™‚)</p>
</section>
<section id="note-on-node-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="note-on-node-embeddings">Note on Node Embeddings</h3>
<p>node embeddingì„ ì°¾ëŠ” ê²ƒì€ unsupervised/self-supervised ë°©ì‹ìœ¼ë¡œ êµ¬ë¶„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´ <strong>node label, node feature ë“±ì„ ì´ìš©í•˜ì§€ ì•Šê³ , graph networkì˜ êµ¬ì¡°ë¥¼ ë³´ì¡´í•œ ì±„ node embeddingì„ ì°¾ê¸° ë•Œë¬¸</strong>ì…ë‹ˆë‹¤. ë”°ë¼ì„œ, í•´ë‹¹ ë°©ë²•ì€ <strong>task independentë¡œ, ì–´ë–¤ taskë“  ì ìš© ê°€ëŠ¥</strong>í•©ë‹ˆë‹¤.</p>
<hr>
</section>
</section>
<section id="random-walk-approaches-for-node-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="random-walk-approaches-for-node-embeddings">3.2 Random Walk Approaches for Node embeddings</h2>
<p>ë³¸ê²©ì ì¸ node embedding ë°©ë²• ì†Œê°œì— ì•ì„œ, <strong>ìš©ì–´</strong>ë¶€í„° ì‚´í´ë´…ì‹œë‹¤!</p>
<ul>
<li><strong>Vector <span class="math inline">\(z_u\)</span> :</strong> node uì˜ <strong>embedding â†’ ìš°ë¦¬ê°€ ì°¾ê³ ì í•˜ëŠ” ê²ƒ.</strong></li>
<li><strong>Probability <span class="math inline">\(P(v|z_u)\)</span> :</strong> node uì—ì„œ ì‹œì‘í•´ì„œ random walkë¡œ node vì— ë°©ë¬¸í•  í™•ë¥ </li>
<li><strong>Non-linear function :</strong></li>
</ul>
<ol type="1">
<li>softmax</li>
</ol>
<p>ì…ë ¥ë°›ì€ ê°’ì„ ì¶œë ¥ìœ¼ë¡œ 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ëª¨ë‘ ì •ê·œí™”í•˜ë©° ì¶œë ¥ê°’ë“¤ì˜ ì´í•©ì€ í•­ìƒ 1ì´ ë˜ëŠ” íŠ¹ì„±ì„ ê°€ì§„ í•¨ìˆ˜ë¡œ, ë¶„ë¥˜í•˜ê³  ì‹¶ì€ class ìˆ˜ë§Œí¼ ì¶œë ¥ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. ê°€ì¥ í° ì¶œë ¥ê°’ì„ ë¶€ì—¬ë°›ì€ classê°€&nbsp;í™•ë¥ ì´ ê°€ì¥ ë†’ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</p>
<ol start="2" type="1">
<li>sigmoid function</li>
</ol>
<p>ëª¨ë“  ì‹¤ìˆ˜ ì…ë ¥ ê°’ì„ 0ë³´ë‹¤ í¬ê³  1ë³´ë‹¤ ì‘ì€ ë¯¸ë¶„ ê°€ëŠ¥í•œ ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” íŠ¹ì§•ì„ ê°–ìŠµë‹ˆë‹¤.</p>
<ul>
<li><strong>Random Walk :</strong></li>
</ul>
<p>node 4ì—ì„œ ì‹œì‘í•œë‹¤ë©´, <strong>ì´ë™ ê°€ëŠ¥í•œ neighbor nodeì¤‘ randomìœ¼ë¡œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì´ë™</strong>í•©ë‹ˆë‹¤. ì´í›„, <strong>ê³ ì •ëœ ìˆ˜ë§Œí¼ ë°˜ë³µì ìœ¼ë¡œ ì´ë™</strong>í•˜ë©´ ë©ë‹ˆë‹¤. random walkë¥¼ ìˆ˜í–‰í•˜ë©´ ê·¸ë˜í”„ìƒì—ì„œ ì´ë™í•œ ì¼ë ¨ì˜ nodeë“¤ì´ ê²°ê³¼ë¡œ ë„ì¶œë©ë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì—ì„œëŠ” <strong>{4,5,8,9,8,11}</strong> ì…ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 4.png" class="img-fluid"></p>
<p>random walkì—ì„œì˜ <span class="math inline">\(**z^T_v z_u\)</span>ëŠ” node uì™€ node vê°€ random walk ì¤‘ ë™ì‹œì— ë°©ë¬¸ ë  í™•ë¥ **ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. random walk ì „ëµ <span class="math inline">\(R\)</span>ì´ ìˆë‹¤ê³  í•  ë•Œ, node uì—ì„œ ì‹œì‘í•˜ì—¬ ì „ëµ <span class="math inline">\(R\)</span>ì— ë”°ë¼ random walkë¥¼ ìˆ˜í–‰í–ˆì„ ë•Œ, node vë¥¼ ë°©ë¬¸í•  í™•ë¥ , <span class="math inline">\(P_R(v|u)\)</span> ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´í›„, ë‘ vector ì‚¬ì´ì˜ ê°ë„ <span class="math inline">\(\theta\)</span>ê°€ <span class="math inline">\(P_R(v|u)\)</span>ì— ë¹„ë¡€í•˜ë„ë¡ embedding ì„ ìµœì í™”í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 5.png" class="img-fluid"></p>
<section id="why-random-walks" class="level3">
<h3 class="anchored" data-anchor-id="why-random-walks">Why Random Walks?</h3>
<p><strong>ì¥ì  1) Expressivity</strong></p>
<p>local(ë³¸ì¸)ë¿ë§Œ ì•„ë‹ˆë¼, higher-order neighborhood(ì—¬ëŸ¬ hop ë–¨ì–´ì§„ ì´ì›ƒ)ë“¤ì˜ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.</p>
<p><strong>ì¥ì  2) Efficiency</strong></p>
<p>ëª¨ë“  nodeë¥¼ í•œêº¼ë²ˆì— ê³ ë ¤í•˜ì§€ ì•Šê³ , random walkë¥¼ í†µí•´ ë°©ë¬¸í•œ nodeë“¤ì˜ ìŒë§Œ ê³ ë ¤í•˜ì—¬ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</section>
<section id="unsupervised-feature-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-feature-learning">Unsupervised Feature Learning</h3>
<p>ë‹¤ì‹œ unsupervised feature learningì—ì„œì˜ ëª©ì ìœ¼ë¡œ ëŒì•„ì™€ ë³´ë©´, ìœ ì‚¬ì„±ì„ ë³´ì¡´í•œ ì±„ node embeddingì„ ì°¾ê³ ì í•©ë‹ˆë‹¤. <strong>ì„¤ë“ë ¥ ìˆëŠ” node embeddingì´ ë˜ê¸° ìœ„í•´ì„œ ê°€ê¹Œìš´(nearby) ë…¸ë“œë¼ë¦¬ ë¹„ìŠ·í•œ embeddingì„ ê°–ë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.</strong></p>
<p>ì ê·¸ëŸ¼ <strong>â€™ê°€ê¹Œìš´â€™ì€ ì–´ë–»ê²Œ ì •ì˜</strong>í•  ìˆ˜ ìˆì„ê¹Œìš”?? ì—¬ê¸°ì„œ random walkê°€ ë“±ì¥í•©ë‹ˆë‹¤!! ë°”ë¡œ <strong>â€™random walkë¡œ ë°©ë¬¸í•˜ê²Œëœ ì´ì›ƒë“¤ì„ â€™ê°€ê¹ë‹¤â€™ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</strong></p>
<blockquote class="blockquote">
<p><span class="math inline">\(N_R(u)\)</span> : random walk ì „ëµ <span class="math inline">\(R\)</span>ì— ë”°ë¼ node uì—ì„œ ì¶œë°œí•˜ì—¬ ë°©ë¬¸í•˜ê²Œëœ ì´ì›ƒë“¤(neighborhood)</p>
</blockquote>
</section>
<section id="feature-learning-as-optimization" class="level3">
<h3 class="anchored" data-anchor-id="feature-learning-as-optimization">Feature Learning as Optimization</h3>
<p>ê·¸ë˜í”„ <span class="math inline">\(G = (V,E)\)</span>ê°€ ì£¼ì–´ì¡Œì„ ë•Œ,</p>
<p><strong>node embedding function, <span class="math inline">\(f: u \rightarrow \R^d : f(u) = z_u\)</span> ì„ ìµœì í™”</strong>í•´ì•¼í•©ë‹ˆë‹¤.</p>
<p>ì´ë¥¼ ìœ„í•´ì„œ, <strong>log-likelihood objectiveëŠ” <span class="math inline">\(max_f \sum_{u\in V}\log P(N_R(u)|z_u)\)</span></strong> ìœ¼ë¡œ, í•´ë‹¹ ê°’ì´ ìµœëŒ€í™” ë˜ëŠ” í•¨ìˆ˜ <span class="math inline">\(f\)</span>ë¥¼ ì°¾ì•„ì•¼í•©ë‹ˆë‹¤.</p>
</section>
<section id="random-walk-optimization" class="level3">
<h3 class="anchored" data-anchor-id="random-walk-optimization">Random Walk Optimization</h3>
<p><strong>Step 1)</strong> random walk strategy <span class="math inline">\(R\)</span>ì— ë”°ë¼ì„œ ê° node uì—ì„œ ê³ ì •ëœ í¬ê¸°ì˜ ì§§ì€ random walkë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>
<p><strong>Step 2)</strong> ê° node ë§ˆë‹¤ multiset ì´ì›ƒ ì§‘í•©, <span class="math inline">\(N_R(u)\)</span>ì„ ëª¨ìë‹ˆë‹¤. *multiset : random walkë™ì•ˆ íŠ¹ì • ë…¸ë“œë¥¼ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¤‘ë³µëœ ì›ì†Œë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p><strong>Step 3)</strong> node uê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì´ì›ƒë“¤ <span class="math inline">\(N_R(u)\)</span> ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ embeddingì„ ìµœì í™”í•©ë‹ˆë‹¤.</p>
<p><span class="math inline">\(max_f \sum_{u\in V}\log P(N_R(u)|z_u)\)</span></p>
<p>ìœ„ ì‹ì€ ëª¨ë“  node u, ê·¸ë¦¬ê³  ê·¸ ê°ê°ì˜ ì´ì›ƒ ë…¸ë“œ vì— ëŒ€í•œ ì‹ìœ¼ë¡œ í’€ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><span class="math inline">\(L = \sum_{u\in V}\sum_{v\in N_R(u)} -\log(P(v|z_u))\)</span>,</p>
</blockquote>
<p>ë˜í•œ, <strong>node uì— ê°€ê¹Œìš´ node vë¥¼ íŒë³„(ë¹„êµ)í•˜ê³ ì í•˜ëŠ” ì ì—ì„œ softmax</strong>ë¥¼ ì‚¬ìš©í•˜ì—¬, <span class="math inline">\(p(v|z_u)\)</span> ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><span class="math inline">\(p(v|z_u) = \frac{exp(z^T_uz_v)}{\sum_{n\in V}exp(z^T_u z_n)}\)</span></p>
</blockquote>
<p><img src="../images/lec03/Untitled 6-1681368211905-8.png" class="img-fluid"></p>
<p>ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œ loss function <span class="math inline">\(L\)</span> ì´ ìµœì†Œí™”ë˜ë„ë¡ <span class="math inline">\(z_u\)</span>ë¥¼ ì°¾ìŠµë‹ˆë‹¤!!</p>
<p>í•˜ì§€ë§Œ, ë‹¤ìŒ ì‹ì€ ë§¤ìš° ê³„ì‚°ì´ expensive í•©ë‹ˆë‹¤. ëª¨ë“  nodeì— ëŒ€í•œ ê³„ì‚°ì´ 2ë²ˆì´ë‚˜(ìœ„ ê·¸ë¦¼ì—ì„œ íŒŒë‘ìƒ‰, ë…¸ë‘ìƒ‰ ë¶€ë¶„ì— í•´ë‹¹) ì¤‘ì²©ë˜ê²Œ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì—, complexityê°€ ë¬´ë ¤ <span class="math inline">\(O(|V|^2)\)</span>ì…ë‹ˆë‹¤.</p>
<p>ì´ë¥¼ ì‹¤ì œì—ì„œ í™œìš©í•˜ê¸° ìœ„í•´ì„ , <strong>softmax í•­ì˜ ë¶„ëª¨ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ ê·¼ì‚¬</strong>í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<p>â†’ ë°©ë²•ì€, <strong>â€˜Negative Samplingâ€™</strong>ì…ë‹ˆë‹¤!!</p>
<p>ëª¨ë“  ë…¸ë“œì— ëŒ€í•œ ê°’ì„ êµ¬í•´ normalizeí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, <strong>kê°œì˜ random negative sampleì— ëŒ€í•´ ì •ê·œí™”ë¥¼ ì§„í–‰</strong>í•©ë‹ˆë‹¤. ì´ë•Œ kê°œì˜ sampleì„ samplingí•  ë•ŒëŠ” degreeì— ê¸°ë°˜í•˜ì—¬ <strong>bias sampling</strong>(<span class="math inline">\(n_i \sim P_v\)</span>)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. <strong>higher degree(undirected graphì˜ ê²½ìš°, ì—°ê²°ëœ edge ìˆ˜)ë¥¼ ê°€ì§ˆìˆ˜ë¡ sample ë  í™•ë¥ ì´ ë†’ì•„</strong>ì§‘ë‹ˆë‹¤. ìƒ˜í”Œì˜ ê°¯ìˆ˜ kê°€ ì»¤ì§ˆ ìˆ˜ë¡, ë” ì •êµí•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, ë™ì‹œì— biasê°€ ì»¤ì§€ëŠ” ë‹¨ì ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ë³´í†µ, këŠ” 5~20ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 7.png" class="img-fluid"></p>
<p><strong>loss functionì„ ìµœì í™”í•  ë•Œ ë³´í†µ stochastic gradient descentë¥¼ ì‚¬</strong>ìš©í•©ë‹ˆë‹¤. gradient descentë€, random pointì—ì„œ ì‹œì‘í•˜ì—¬ ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ê³  learning rateì— ë§ê²Œ ë°©í–¥ì„ ì¡°ê¸ˆì”© ë³€í™”í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ìˆ˜ë ´í•  ë•Œ ê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤. íŠ¹íˆ, stochastic gradient descentëŠ” ëª¨ë“  exampleì— ëŒ€í•´ì„œ í•´ë‹¹ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë§¤ë²ˆ ëœë¤ìœ¼ë¡œ ì„ íƒí•œ í•˜ë‚˜ì˜ exampleì— ëŒ€í•´ì„œë§Œ ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ê³  ì—…ë°ì´íŠ¸ í•´ë‚˜ê°‘ë‹ˆë‹¤.</p>
<p>ì ì—¬ê¸°ê¹Œì§€ <strong>Random Walk ê³¼ì •ì„ ìš”ì•½</strong>í•´ë³´ìë©´,</p>
<p><strong>Step 1)</strong> random walk strategy <span class="math inline">\(R\)</span>ì— ë”°ë¼ì„œ ê° node uì—ì„œ ê³ ì •ëœ í¬ê¸°ì˜ ì§§ì€ random walkë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>
<p><strong>Step 2)</strong> ê° node ë§ˆë‹¤ multiset ì´ì›ƒ ì§‘í•©, <span class="math inline">\(N_R(u)\)</span>ì„ ëª¨ìë‹ˆë‹¤.</p>
<p><strong>Step 3)</strong> loss funcion : <span class="math inline">\(L = \sum_{u\in V}\sum_{v\in N_R(u)} -\log(P(v|z_u))\)</span> ë‹¤ìŒ loss functionì„ negative samplingì„ ì‚¬ìš©í•´ softmax ë¶€ë¶„ì„ ê·¼ì‚¬í•˜ê³ , stochastic gradient descentë¥¼ í†µí•´ ìµœì í™”ì—¬ embeddingì„ êµ¬í•©ë‹ˆë‹¤.</p>
</section>
<section id="how-should-we-randomly-walk" class="level3">
<h3 class="anchored" data-anchor-id="how-should-we-randomly-walk">How should we randomly walk?</h3>
<p>ê·¸ë ‡ë‹¤ë©´ <strong>íš¨ê³¼ì ì¸ random walk ì „ëµ <span class="math inline">\(R\)</span>ì€ ë¬´ì—‡</strong>ì¼ê¹Œìš”?? ê³ ì • í¬ê¸° ë§Œí¼ì˜ random walkì™€ ê°™ì€ ë‹¨ìˆœí•œ ë°©ë²•ì€ ìœ ì‚¬ì„±ì„ í‘œí˜„í•˜ê¸°ì— ë§¤ìš° í•œì •ì ì…ë‹ˆë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ë°©ë²•ì´ <strong>node2vec</strong> ì…ë‹ˆë‹¤. í‘œí˜„ë ¥ì´ ì¢‹ì€ (expressive)í•œ ì´ì›ƒë“¤ì„ ëª¨ìœ¼ê¸° ìœ„í•´ <strong>â€˜biased 2nd order random walk <span class="math inline">\(R\)</span>â€™</strong> ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>
</section>
<section id="node2vec-biased-walks" class="level3">
<h3 class="anchored" data-anchor-id="node2vec-biased-walks">node2vec : Biased Walks</h3>
<p>í•µì‹¬ ì•„ì´ë””ì–´ëŠ” <strong>local + global íƒìƒ‰ì˜ tradeoffë¥¼ ì˜ ê³ ë ¤í•˜ì—¬ biased walkë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒ</strong>ì…ë‹ˆë‹¤. ì´ë•Œ <strong>localì€ BFS(Breadth-First Search) ë„ˆë¹„ ìš°ì„  íƒìƒ‰ì„ í†µí•´, globalì€ DFS(Depth-First Search) ê¹Šì´ ìš°ì„  íƒìƒ‰</strong>ì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 8.png" class="img-fluid"></p>
</section>
<section id="interpolating-bfs-and-dfs" class="level3">
<h3 class="anchored" data-anchor-id="interpolating-bfs-and-dfs">Interpolating BFS and DFS</h3>
<p>node u ì— ëŒ€í•œ <span class="math inline">\(N_R(u)\)</span>ë¥¼ ëª¨ì„ ë•Œ, 2ê°€ì§€ hyper-parameterë¥¼ ì§€ì •í•˜ì—¬ BFSì™€ DFS ë°©ë²•ì„ ë™ì‹œì— ì ì ˆíˆ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p><strong>1) return parameter <span class="math inline">\(p\)</span> :</strong> ì´ì „ nodeë¡œ ëŒì•„ê°ˆ í™•ë¥ </p>
<p><strong>2) in-out parameter <span class="math inline">\(q\)</span> :</strong> BFS(inwards)ì™€ DFS(outwards)ê°„ì˜ ë¹„ìœ¨(ratio)</p>
</section>
<section id="biased-2nd-order-random-walks" class="level3">
<h3 class="anchored" data-anchor-id="biased-2nd-order-random-walks">Biased 2nd-order random walks</h3>
<p>ë‹¤ìŒ ê·¸ë¦¼ì€ random walk ì¤‘ node <span class="math inline">\(s_1\)</span>ì—ì„œ node <span class="math inline">\(w\)</span>ë¡œ ì´ë™í•œ ìƒí™©ì…ë‹ˆë‹¤.</p>
<p>ì´ì œ <span class="math inline">\(w\)</span>ì—ì„œ ì·¨í•  ìˆ˜ ìˆëŠ” í–‰ë™ ìœ í˜•ì€ ì´ 3ê°€ì§€, &lt;<strong>(1) ì´ì „ ë…¸ë“œ <span class="math inline">\(s_1\)</span>ìœ¼ë¡œ ëŒì•„ê°€ê¸°, (2) <span class="math inline">\(s_1\)</span>ì—ì„œ ë™ì¼í•˜ê²Œ 1 hop ë–¨ì–´ì ¸ ìˆëŠ” <span class="math inline">\(s_2\)</span>ë¡œ ì´ë™, (3)ë” ë©€ë¦¬ <span class="math inline">\(s_3, s_4\)</span>ë¡œ ì´ë™</strong> &gt;ì´ ìˆìŠµë‹ˆë‹¤. ì•ì„œ ì •ì˜í–ˆë˜ parameterë“¤ì„ ì ìš©í•´ë³´ë©´, <span class="math inline">\(1/p\)</span>ê°€ ë‹¤ì‹œ ëŒì•„ê°ˆ í™•ë¥ , <span class="math inline">\(1/q\)</span> ë¥¼ ë” ë©€ë¦¬ ì´ë™í•  í™•ë¥ ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´í›„, <span class="math inline">\(w\)</span>ì—ì„œì˜ 4ê°€ì§€ ì„ íƒì§€(<span class="math inline">\(s_1, s_2, s_3,s_4\)</span>)ì— ëŒ€í•œ í™•ë¥ ì„ 1ë¡œ ë§ì¶”ì–´ ì •ê·œí™”í•©ë‹ˆë‹¤. BFSì™€ ê°™ì´ inwardsë¥¼ ëŒì•„ë‹¤ë‹ˆê²Œ í•˜ë ¤ë©´ pê°’ì„ ë‚®ì¶”ë©´ ë˜ê³ , DFSì™€ ê°™ì´ outwardsë¥¼ ëŒì•„ë‹¤ë‹ˆë ¤ë©´ qê°’ì„ ë‚®ì¶”ë©´ ë©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 9.png" class="img-fluid"></p>
</section>
<section id="node2vec-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="node2vec-algorithm">node2vec algorithm</h3>
<p><strong>Step 1)</strong> random walk í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.</p>
<p><strong>Step 2)</strong> ê° ë…¸ë“œ u ì—ì„œ ê¸¸ì´ <span class="math inline">\(l\)</span> ë§Œí¼ì˜ random walkë¥¼ <span class="math inline">\(r\)</span>ë²ˆ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.</p>
<p><strong>Step 3)</strong> Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ node2vec objective functionì„ ìµœì í™”í•©ë‹ˆë‹¤.</p>
<p>ì‹œê°„ ë³µì¡ë„ëŠ” linear-timeì´ë©°, ê° stepì´ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ, í•´ë‹¹ ë°©ë²•ì˜ ë‹¨ì ì€ ëª¨ë“  nodeë“¤ì´ ê°ê°ì˜ node embeddingì„ í•™ìŠµí•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê·¸ë˜í”„ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡, ë” ë§ì€ embeddingì„ í•™ìŠµí•´ì•¼ í•©ë‹ˆë‹¤.</p>
<ul>
<li>ì¼ë°˜ì ìœ¼ë¡œ node2vecì€ node classificationì„ ì˜ ìˆ˜í–‰í•œë‹¤ê³  ì•Œë ¤ì ¸ìˆìœ¼ë©°, random walkëŠ” ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ <strong>ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€ëŠ” ë³¸ì¸ì˜ ì—°êµ¬ì— ì œì¼ ì˜ ë§ëŠ” ë°©ë²•ì„ ì±„íƒ</strong>í•´ì•¼ í•©ë‹ˆë‹¤.</li>
</ul>
<hr>
</section>
</section>
<section id="embedding-entire-graphs" class="level2">
<h2 class="anchored" data-anchor-id="embedding-entire-graphs">3.3 Embedding Entire Graphs</h2>
<p>3ì¥ì—ì„œëŠ” node levelì—ì„œ ë²—ì–´ë‚˜ <strong>ê·¸ë˜í”„ ì „ì²´ë¥¼ embedding</strong> í•´ë´…ì‹œë‹¤.</p>
<p><img src="../images/lec03/Untitled 10.png" class="img-fluid"></p>
<p><strong>ë°©ë²• 1) node embeddingì˜ í•©</strong></p>
<p>random walk í˜¹ì€ node2vecì—ì„œ êµ¬í•œ node embeddingì„ ì´ìš©í•˜ì—¬ ê³„ì‚°(í•©/í‰ê· ) í•©ë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><span class="math inline">\(z_G = \sum_{v\in G }z_v\)</span></p>
</blockquote>
<ul>
<li>í•´ë‹¹ ë°©ë²•ì€ moleculesë¥¼ ë¶„ë¥˜í•˜ëŠ” ì—°êµ¬ì— ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.</li>
</ul>
<p><strong>ë°©ë²• 2) â€˜virtual nodeâ€™</strong></p>
<p>ê·¸ë˜í”„ì˜ <strong>íŠ¹ì • ë¶€ë¶„ì„ ëŒ€í‘œí•˜ëŠ” â€™virtual nodeâ€™ë¥¼ ì¶”ì¶œ</strong>í•˜ê³ , ì—¬ê¸°ì— graph embedding ê¸°ìˆ ì„ ì ìš©í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 11.png" class="img-fluid"></p>
<p><strong>ë°©ë²• 3) Anonymous Walk Embeddings</strong></p>
<p>ì²« ë²ˆì§¸ë¡œ <strong>ë°©ë¬¸í•œ nodeë¶€í„° ìˆœì„œëŒ€ë¡œ indexë¥¼ ë¶€ì—¬</strong>í•©ë‹ˆë‹¤. <strong>random walk ë¡œ ì´ë™í•˜ë©´ì„œ index sequenceë¥¼ ê¸°ë¡</strong>í•©ë‹ˆë‹¤. ë°©ë¬¸í•œ nodeê°€ ì‹¤ì œ ì–´ë–¤ nodeì¸ì§€ ìƒê´€ì—†ì´ ë°©ë¬¸í•œ ìˆœì„œì— ë”°ë¼ indexê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 12.png" class="img-fluid"></p>
<p>random walk ê¸¸ì´ê°€ 3ì¼ë•Œ, ê°€ëŠ¥í•œ anonymous walkì˜ ìˆ˜ëŠ” ì´ 5ê°œ ì…ë‹ˆë‹¤. â†’ <span class="math inline">\(w_1=111,w_2=112,w_3=121,w_4=122,w_5=123\)</span></p>
<p><strong>ê°€ëŠ¥í•œ anonymous walkìˆ˜ëŠ” random walk ê¸¸ì´ì— ë”°ë¼ exponentialí•˜ê²Œ ì¦ê°€</strong>í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 13.png" class="img-fluid"></p>
<section id="simple-use-of-anonymous-walks" class="level3">
<h3 class="anchored" data-anchor-id="simple-use-of-anonymous-walks">Simple Use of Anonymous Walks</h3>
<p>step ìˆ˜ <span class="math inline">\(l\)</span> ì„ ì •í•œ ë’¤, <strong>ê°€ëŠ¥í•œ anonymous walkë¥¼ ê³„ì‚°</strong>í•©ë‹ˆë‹¤. ì´í›„ <strong>ê° walkì— ëŒ€í•œ probability distributionì„ ê³„ì‚°</strong>í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, <span class="math inline">\(l=3\)</span>ì¼ ë•Œ ê°€ëŠ¥í•œ walkëŠ” 5ê°œì˜€ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê° 5ê°œ walkì— ëŒ€í•œ í™•ë¥ ì„ ê³„ì‚°í•˜ì—¬, í•´ë‹¹ ê·¸ë˜í”„ë¥¼ <strong>5ì°¨ì›ì˜ vectorë¡œ í‘œí˜„</strong>í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<blockquote class="blockquote">
<p><span class="math inline">\(Z_G[i]\)</span> = probability of anonymous walk <span class="math inline">\(w_i\)</span></p>
</blockquote>
</section>
<section id="sampling-anonymous-walks" class="level3">
<h3 class="anchored" data-anchor-id="sampling-anonymous-walks">Sampling Anonymous Walks</h3>
<p>ê·¸ë ‡ë‹¤ë©´ ì ë‹¹í•œ random walkëŠ” ëª‡ ê°œ ì¼ê¹Œìš”? <span class="math inline">\(\delta\)</span>ì˜ í™•ë¥ ë³´ë‹¤ ë‚®ê²Œ <span class="math inline">\(\epsilon\)</span> ì´ìƒì˜ errorë¥¼ ê°–ê²Œ í•˜ê¸° ìœ„í•´ì„  ë‹¤ìŒ ì‹ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 14.png" class="img-fluid"></p>
</section>
<section id="new-idea-learn-walk-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="new-idea-learn-walk-embeddings">New idea : Learn Walk Embeddings</h3>
<p>ìƒˆë¡œìš´ ì•„ì´ë””ì–´ëŠ” anonymous walk <span class="math inline">\(w_i\)</span>ì˜ embedding <span class="math inline">\(z_i\)</span>ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´, ê·¸ë˜í”„ embeddingì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. <span class="math inline">\(Z = \{z_i : i = 1 \dots \eta \},\;\eta\)</span> : sampled anonymous walks ê°¯ìˆ˜</p>
<p><strong>anynomous random walkë¥¼ ìƒ˜í”Œë§</strong>í•©ë‹ˆë‹¤. <strong>ì´í›„ <span class="math inline">\(\Delta\)</span>-size window ë‚´ì— ì–´ë–¤ walk ê°€ í•¨ê»˜ ë°œìƒí• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.</strong> ì˜ˆë¥¼ ë“¤ì–´, <span class="math inline">\(\Delta\)</span>ê°€ 1ì¼ ë•Œ ê²½ìš°, <strong>ì§ì „ê³¼ ì§í›„ì— ì–´ë–¤ walkê°€ ë°œìƒí•  ì§€ ì˜ˆì¸¡</strong>í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ í’€ì–´ë³´ë©´ objectiveëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. graph embedding <span class="math inline">\(Z_G\)</span>ì™€ time window ë‚´ì— walkë“¤(<span class="math inline">\(w_{t-\Delta}, \dots, w_{t+\Delta}\)</span>)ì´ ì£¼ì–´ì¡Œì„ ë•Œ <span class="math inline">\(w_t\)</span>ì— ëŒ€í•œ log probabilityë¥¼ ìµœëŒ€í™”í•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  nodeê°€ ì¶œë°œì ì´ ë˜ì–´ì„œ ê°ê°ì˜ objectiveë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ëª¨ë‘ ë”í•©ë‹ˆë‹¤.</p>
<p><img src="../images/lec03/Untitled 15.png" class="img-fluid"></p>
<p>ì´ì œ <strong>node u ì˜ ì´ì›ƒ <span class="math inline">\(N_R(u)\)</span>ì€ random walk ì˜ setìœ¼ë¡œ í‘œí˜„</strong>ë©ë‹ˆë‹¤.</p>
<p><span class="math inline">\(N_R(u) = \{w_1^u, w_2^u,\dots, w_T^u\}\)</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/lec03/Untitled 16.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Untitled 16</figcaption><p></p>
</figure>
</div>
<p>ë‹¤ìŒê³¼ ê°™ì´ graph embedding <span class="math inline">\(Z_G\)</span>ë¥¼ êµ¬í•œë’¤, inner product í˜¹ì€ neural networkë¥¼ ê±°ì³ graph classificationê³¼ ê°™ì€ ì˜ˆì¸¡ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</section>
<section id="summary-of-graph-embedding" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-graph-embedding">Summary of Graph embedding</h3>
<p>ì§€ê¸ˆê¹Œì§€, <strong>ì´ 3ê°€ì§€ ê·¸ë˜í”„ embedding ë°©ë²•</strong>ì— ëŒ€í•´ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤.</p>
<p><strong>ë°©ë²• 1)</strong> deep walk í˜¹ì€ node2vecìœ¼ë¡œ êµ¬í•œ node embeddingì„ í•©í•˜ê±°ë‚˜ í‰ê· ë‚´ê¸°</p>
<p><strong>ë°©ë²• 2)</strong> virtual nodeì™€ ê°™ì´ super-nodeêµ¬í•´ì„œ embeddingí•˜ê¸°</p>
<p><strong>ë°©ë²• 3)</strong> Anonymous Walk Embedding</p>
<p><strong>3-1)</strong> anonymous walk sampleì„ êµ¬í•œ ë’¤, ê°ê°ì˜ walkê°€ ëª‡ë²ˆ ë°œìƒí–ˆëŠ”ì§€ ë¹„ìœ¨ ê³„ì‚°</p>
<p><strong>3-2)</strong> anonymous walkë¥¼ embeddingí•˜ê³  ì´ë¥¼ í•©ì³ graph embeddingí•˜ê¸°</p>
<p>*ì°¨í›„ì˜ ê°•ì˜ì—ì„œëŠ” Hierarchical Embeddingì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤(Lecture 8).</p>
<p>graphìƒì˜ nodeë“¤ì„ ê³„ì¸µì ìœ¼ë¡œ ë¬¶ì€ ë’¤, ì´ë“¤ì„ í•©/í‰ê·  ë‚´ì–´ graph embedding í•©ë‹ˆë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/lec03/Untitled 17.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Untitled 17</figcaption><p></p>
</figure>
</div>
</section>
<section id="how-to-use-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="how-to-use-embeddings">How to Use Embeddings</h3>
<p>ì—´ì‹¬íˆ êµ¬í•œ embeddingì€ ì•„ë˜ì™€ ê°™ì´ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤ğŸ™‚ğŸ™‚</p>
<p><strong>1)</strong> Clustering/ community detection</p>
<p><strong>2)</strong> Node classification</p>
<dl>
<dt><strong>3)</strong> Link Prediction</dt>
<dd>
<p>2ê°œì˜ embedding(<span class="math inline">\(z_i,z_j\)</span>)ì— ëŒ€í•´ concatenate, hadamard, sum/avg, distance ê³„ì‚°</p>
</dd>
</dl>
<p><strong>4)</strong> Graph classification</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>