<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JooHo Kim">
<meta name="dcterms.date" content="2022-07-07">
<meta name="description" content="Traditional Methods for ML on Graphs">

<title>CS224W-KOR Blog - Lecture 2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS224W-KOR Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">Study Group</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/CS224W-KOR"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Lecture 2</h1>
                  <div>
        <div class="description">
          Traditional Methods for ML on Graphs
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LEC02</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>JooHo Kim </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 7, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#traditional-ml-pipeline" id="toc-traditional-ml-pipeline" class="nav-link active" data-scroll-target="#traditional-ml-pipeline">💡Traditional ML Pipeline</a></li>
  <li><a href="#lecture-object-feature-design" id="toc-lecture-object-feature-design" class="nav-link" data-scroll-target="#lecture-object-feature-design">💡 Lecture Object : Feature Design</a></li>
  <li><a href="#traditional-feature-based-method-node" id="toc-traditional-feature-based-method-node" class="nav-link" data-scroll-target="#traditional-feature-based-method-node">🔴&nbsp;Traditional Feature-Based Method : Node</a>
  <ul class="collapse">
  <li><a href="#node-degree-k_v" id="toc-node-degree-k_v" class="nav-link" data-scroll-target="#node-degree-k_v">💡 1. Node Degree (<span class="math inline">\(k_v\)</span>)</a></li>
  <li><a href="#node-centralityc_v" id="toc-node-centralityc_v" class="nav-link" data-scroll-target="#node-centralityc_v">💡 2. Node Centrality(<strong><span class="math inline">\(c_v\)</span></strong>)</a></li>
  <li><a href="#clustering-coefficient" id="toc-clustering-coefficient" class="nav-link" data-scroll-target="#clustering-coefficient">💡 3. Clustering Coefficient</a></li>
  <li><a href="#graphlets" id="toc-graphlets" class="nav-link" data-scroll-target="#graphlets">🤔 4. Graphlets***</a></li>
  <li><a href="#node-level-feature-summary" id="toc-node-level-feature-summary" class="nav-link" data-scroll-target="#node-level-feature-summary">💡 Node-Level Feature Summary</a></li>
  </ul></li>
  <li><a href="#traditional-feature-based-method-link" id="toc-traditional-feature-based-method-link" class="nav-link" data-scroll-target="#traditional-feature-based-method-link">🔗&nbsp;Traditional Feature-Based Method : Link</a>
  <ul class="collapse">
  <li><a href="#link-level-prediction-task" id="toc-link-level-prediction-task" class="nav-link" data-scroll-target="#link-level-prediction-task">💡 Link-Level Prediction Task</a></li>
  <li><a href="#link---level-feature-distance-based-features" id="toc-link---level-feature-distance-based-features" class="nav-link" data-scroll-target="#link---level-feature-distance-based-features">💡 Link - Level Feature : Distance-Based Features</a></li>
  <li><a href="#link-level-feature-summary" id="toc-link-level-feature-summary" class="nav-link" data-scroll-target="#link-level-feature-summary">💡Link-Level Feature Summary</a></li>
  </ul></li>
  <li><a href="#traditional-feature-based-method-graph" id="toc-traditional-feature-based-method-graph" class="nav-link" data-scroll-target="#traditional-feature-based-method-graph">⛓&nbsp;Traditional Feature-Based Method : Graph</a>
  <ul class="collapse">
  <li><a href="#kernel-method" id="toc-kernel-method" class="nav-link" data-scroll-target="#kernel-method">💡 Kernel Method</a></li>
  <li><a href="#grahplet-features" id="toc-grahplet-features" class="nav-link" data-scroll-target="#grahplet-features">💡 Grahplet Features</a></li>
  <li><a href="#graphlet-kernel" id="toc-graphlet-kernel" class="nav-link" data-scroll-target="#graphlet-kernel">💡 Graphlet Kernel</a></li>
  <li><a href="#weisfeiler-lehmanwl-kernel" id="toc-weisfeiler-lehmanwl-kernel" class="nav-link" data-scroll-target="#weisfeiler-lehmanwl-kernel">💡 Weisfeiler-Lehman(WL) Kernel</a></li>
  <li><a href="#color-refinement" id="toc-color-refinement" class="nav-link" data-scroll-target="#color-refinement">💡 Color Refinement</a></li>
  <li><a href="#graph-level-feature-summary" id="toc-graph-level-feature-summary" class="nav-link" data-scroll-target="#graph-level-feature-summary">💡 <strong><em>Graph-Level Feature Summary</em></strong></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>2강에선 Graph를 이용한 Traditional ML 방법론들에 대해 설명한다.</p>
<section id="traditional-ml-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="traditional-ml-pipeline">💡Traditional ML Pipeline</h3>
<p><strong><em>Traditional ML Pipeline</em></strong>은 크게 2단계로 이루어져 있다.</p>
<ol type="1">
<li>Data Point, Node, Link, Graph(이하 <strong>입력</strong>)를 Feature Vector로 변환해 ML모델을 학습시킨다.</li>
<li>새로운 <strong>입력</strong>이 들어오면 Feature Vector를 얻고 모델을 통해 예측한다.</li>
</ol>
<hr>
</section>
<section id="lecture-object-feature-design" class="level3">
<h3 class="anchored" data-anchor-id="lecture-object-feature-design">💡 Lecture Object : Feature Design</h3>
<hr>
<p><code>Goal</code> : <strong>입력</strong> Set이 주어졌을때 예측값을 만들어내는것 / 모델은 ML Model 사용</p>
<blockquote class="blockquote">
<p>Design Choice</p>
<ul>
<li>Feature : <span class="math inline">\(d\)</span>차원의 벡터</li>
<li>입력 : Nodes, Links, Sets of Nodes, Entire Graph</li>
<li>Objective Function : 무슨 Task를 풀려고 하는가?</li>
</ul>
</blockquote>
<hr>
<ol type="1">
<li>Traditional ML Pipeline은 수작업으로 만들어진(Hand-Designed) Feature를 사용한다.</li>
<li>Hand Designed Feature를 Graph의 세 레벨 (Node, Link, Graph)로 나누어 설명한다.</li>
<li>Undirected Graph를 중점으로 설명한다.</li>
</ol>
<hr>
</section>
<section id="traditional-feature-based-method-node" class="level2">
<h2 class="anchored" data-anchor-id="traditional-feature-based-method-node">🔴&nbsp;Traditional Feature-Based Method : Node</h2>
<blockquote class="blockquote">
<p><strong>Goal : Network에서 Node의 구조와 위치를 특정할 수 있는 Feature를 만드는 것</strong></p>
</blockquote>
<section id="node-degree-k_v" class="level3">
<h3 class="anchored" data-anchor-id="node-degree-k_v">💡 1. Node Degree (<span class="math inline">\(k_v\)</span>)</h3>
<p>Node <span class="math inline">\(v\)</span> 의 Degree를 <span class="math inline">\(k_v\)</span> 라고 정의하자. 이때 <span class="math inline">\(k_v\)</span> 는 <span class="math inline">\(v\)</span> 가 갖고있는 Edge(Link)의 수와 같다.</p>
<p><img src="https://i.imgur.com/bRvU9Xz.png" class="img-fluid"></p>
</section>
<section id="node-centralityc_v" class="level3">
<h3 class="anchored" data-anchor-id="node-centralityc_v">💡 2. Node Centrality(<strong><span class="math inline">\(c_v\)</span></strong>)</h3>
<p>Node Degree는 단순히 이웃한 Node의 갯수를 세므로, 그것들의 중요도를 Capture할 수 없다.</p>
<p>Node Centrality(<span class="math inline">\(c_v\)</span>)는 Graph에서 해당 Node( <span class="math inline">\(v\)</span>)의 중요도를 포함시킨 개념이다.</p>
<ul>
<li><strong>2-1. Engienvector centrality</strong>
<ul>
<li><code>Important</code> : <span class="math inline">\(v\)</span>가 <em>Important</em> 이웃노드 <span class="math inline">\(u\)</span>에 둘러싸여 있을 때 <span class="math inline">\(v\)</span>는 <em>Important</em>하다고 한다.</li>
<li><code>Formula</code>
<ul>
<li><span class="math inline">\(c_v = {1 \over \lambda} \sum\limits_{u\in N(v)}c_u\)</span> (<span class="math inline">\(\lambda\)</span>는 Normalization 상수) ⇒ 이렇게 하면 Recursive함</li>
<li><span class="math inline">\(\lambda c= Ac\)</span> (<span class="math inline">\(A\)</span>는 Adjacency Matrix)
<ul>
<li>고유값과 고유벡터 형태로 재설정</li>
<li><span class="math inline">\(c\)</span>는 <span class="math inline">\(A\)</span>의 고유벡터, <span class="math inline">\(\lambda\)</span>는 고유값이며 <span class="math inline">\(\lambda_{max}\)</span>는 항상 양수에 Unique함</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>2-2. Betweenness centrality</strong>
<ul>
<li><p><code>Important</code> : <span class="math inline">\(v\)</span>가 다른 노드들을 연결하는 최단 경로에 있을때 <em>Important</em>하다고 한다.(경유)</p></li>
<li><p><code>Formula</code> : <span class="math inline">\(c_v = \sum\limits_{s \neq v \neq t}{v를\ 포함하는 s와\ t사이 \ 최단\ 경로 \over s와\ t사이\ 최단\ 경로}\)</span></p>
<p><img src="https://i.imgur.com/xh0zsGH.png" class="img-fluid"></p></li>
</ul></li>
<li><strong>2-3. Closeness Centrality</strong>
<ul>
<li><p><code>Important</code> : <span class="math inline">\(v\)</span>가 다른 모든 노드에 대한 최단 경로의 길이가 짧을때 <em>Important</em>하다고 한다.</p></li>
<li><p><code>Formula</code> : <span class="math inline">\(c_v = 1 \div \sum\limits_{u \neq v} (u와\ v사이의\ 최단경로의\ 길이)\)</span></p>
<p><img src="https://i.imgur.com/QA0e7Hi.png" class="img-fluid"></p></li>
</ul></li>
</ul>
<hr>
</section>
<section id="clustering-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="clustering-coefficient">💡 3. Clustering Coefficient</h3>
<p><strong><em>Clustering Coefficient</em></strong>는 Node <span class="math inline">\(v\)</span>의 이웃들이 얼마나 연결되어 있는지를 측정하는 개념이다.</p>
<p><span class="math inline">\(v\)</span>의 이웃간 연결된 경우의 수를 이웃 Node들이 서로 연결될 수 있는 전체 경우의 수로 나누어준다.</p>
<p><img src="https://i.imgur.com/WSxpVTm.png" class="img-fluid"></p>
<p><img src="https://i.imgur.com/g7wDAiK.png" class="img-fluid"></p>
<hr>
</section>
<section id="graphlets" class="level3">
<h3 class="anchored" data-anchor-id="graphlets">🤔 4. Graphlets***</h3>
<hr>
<p><code>Observation</code> : Clustering Coefficient는 Ego-Network의 #(Triangle)을 센다)</p>
<ul>
<li>Ego-Network : Node가 주어졌을때 자기자신과 1차-이웃만 포함한 Network</li>
<li>#(Triangle) : 3개의 노드가 연결되어 있는 것</li>
<li>이런 Triangle Counting을 다양한 구조에 대해 일반화 하는것 ⇒ Graphlets의 개념</li>
</ul>
<p><img src="https://i.imgur.com/oANu76X.png" class="img-fluid"></p>
<hr>
<ul>
<li>Graphlet의 목적 : Node <span class="math inline">\(u\)</span>의 이웃 구조를 기술하는 것
<ul>
<li><p>Graphlets : <span class="math inline">\(u\)</span>의 이웃 구조를 기술하기 위한 작은 Subgraph(Template?)</p>
<p><img src="https://i.imgur.com/Rih91Sq.png" class="img-fluid"></p></li>
</ul></li>
</ul>
<hr>
<blockquote class="blockquote">
<p><strong><em>Graphlet Degree Vector(GDV)</em></strong> : Node의 Graphelt-Based Feature</p>
<ul>
<li>Degree of Graphlet : 특정 Node가 포함된 Graphlet의 갯수 벡터이다. 어떻게 세는지는 아래의 예시를 통해 설명한다.</li>
</ul>
</blockquote>
<hr>
<ol type="1">
<li><p>아래와 같이 생긴 Graph <span class="math inline">\(G\)</span>에서 Node <span class="math inline">\(u\)</span>에 관심있다고 가정해 보자.</p>
<p><img src="https://i.imgur.com/6wbUZqm.png" class="img-fluid"></p></li>
<li><p>Graph 구조를 보았을때, 최대 3개의 Node가 참여하는 Graphlet을 만들 수 있다.</p>
<p><img src="https://i.imgur.com/3uIYSMl.png" class="img-fluid"></p></li>
<li><p>각각의 Graphlet이 <span class="math inline">\(G\)</span>에서 <span class="math inline">\(u\)</span>를 포함한채로 몇번 나타나는지 세보자</p>
<p><img src="https://i.imgur.com/3HqOtKv.png" class="img-fluid"></p></li>
<li><p>Node <span class="math inline">\(u\)</span>의 GDV는 [2,1,0,2]가 된다.</p></li>
</ol>
<blockquote class="blockquote">
<p><strong><em>Graphlet Summary</em></strong></p>
</blockquote>
<pre><code>2~5개의 Node가 참여하는 Graphlet의 갯수는 73개이다. 이를 73차원의 벡터로 표시할 수 있고, 각 Index는 특정한 Neighborhood Topology에 Signature이다. 이 벡터를 이용해 Node의 Local Network Topology를 잘 정제된 Feature로 만든게 GDV이며, 앞에서 소개한 방식보다 자세한 정보를 갖고있다.</code></pre>
</section>
<section id="node-level-feature-summary" class="level3">
<h3 class="anchored" data-anchor-id="node-level-feature-summary">💡 Node-Level Feature Summary</h3>
<pre><code>Node Level Feature는 2가지 분류로 나눌수 있다

1. Importance Based (Ex Task : 영향력있는 Node찾기(SNS의 셀럽찾기))
    1. Node Degree : 단순히 이웃의 숫자를 센다
    2. Node Centrality : Graph에서의 이웃 노드의 중요도를 모델링한다.
2. Structure Based (Ex Task : Node의 역할 찾기(단백질 구조에서 특정 단백질의 기능찾기))
    1. Node Degree : 단순히 이웃의 숫자를 센다
    2. Clustering Coefficient : 이웃이 어떻게 연결되어있는지 측정한다.
    3. Graphlet Count Vector : 여러 Graphlet들이 출현하는 빈도를 센다.</code></pre>
<hr>
</section>
</section>
<section id="traditional-feature-based-method-link" class="level2">
<h2 class="anchored" data-anchor-id="traditional-feature-based-method-link">🔗&nbsp;Traditional Feature-Based Method : Link</h2>
<hr>
<section id="link-level-prediction-task" class="level3">
<h3 class="anchored" data-anchor-id="link-level-prediction-task">💡 Link-Level Prediction Task</h3>
<p>Link-Level Task는 존재하는 Link를 바탕으로 새로운 Link를 예측하는 것이다. Link를 예측하는 Task는 크게 2가지 Formulation이 있다.</p>
<blockquote class="blockquote">
<p><strong><em>1. 랜덤하게 사라진 Link 찾기 :</em></strong> Static한 Graph에 적절하다.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong><em>2. 시간이 흐름에 따라 생겨나는 Link 찾기 :</em></strong> SNS, Transaction같이 Dynamic한 Graph에 적절하다.</p>
</blockquote>
<p>Link-Level Prediction의 자세한 방법은 다음과 같다.</p>
<ol type="1">
<li>각 Node쌍 (<span class="math inline">\(x,y)\)</span>에 score <span class="math inline">\(c(x,y)\)</span>를 계산한다.</li>
<li><span class="math inline">\(c(x,y)\)</span> 내림차순으로 Node 쌍을 정렬한다</li>
<li>Top <span class="math inline">\(N\)</span>개의 Pair들을 새로운 Link로 예측한다.</li>
</ol>
<hr>
</section>
<section id="link---level-feature-distance-based-features" class="level3">
<h3 class="anchored" data-anchor-id="link---level-feature-distance-based-features">💡 Link - Level Feature : Distance-Based Features</h3>

<blockquote class="blockquote">
<p><strong><em>1. 노드간 최단 경로</em></strong></p>
</blockquote>
<p>두 Node간 최단경로의 거리를 사용한다. 이웃의 수나 강도에 대한 어떠한 정보도 캡쳐하지 않는다.</p>
<blockquote class="blockquote">
<p><strong><em>2. Local Neighborhood Overlap</em></strong></p>
</blockquote>
<p>두 Node가 공유하는 이웃을 캡쳐한다.</p>
<ul>
<li><strong>Coomon Neighbors</strong> : 단순히 교집합을 구한다</li>
<li><strong>Jaccard’s Coefficient</strong> : 교집합의 크기를 합집합으로 나눈다</li>
<li><strong>Adamic-Adar Index</strong> : (SNS에서 잘 동작한다고 하네요) 두 Node가 공유하는 이웃을 u라고 할 때 <span class="math inline">\(\sum \limits_u {1\over log(k_u)}\)</span></li>
</ul>
<blockquote class="blockquote">
<p><strong><em>3. Global Neighborhood Overlap</em></strong></p>
</blockquote>
<p>Local Neighborhood Overlap의 단점은 잠재적 이웃도 직접적인 공통 이웃이 없으면 0이 된다는 점이다.</p>
<p><img src="https://i.imgur.com/xWSmHWZ.png" class="img-fluid"></p>
<ul>
<li><strong>Katz Index</strong> : 주어진 Node 쌍을 잇는 모든 길이의 경로를 센다. Matrix를 이용해 깔끔하게 연산할수 있다.
<ul>
<li><span class="math inline">\(A_{uv}\)</span>는 직접 이웃일 때 1이고 아니면 0이다.</li>
<li><span class="math inline">\(P_{uv}^{(K)}\)</span>는 <span class="math inline">\(K\)</span>길이의 <span class="math inline">\(u,v\)</span>를 잇는 경로이다.</li>
<li><span class="math inline">\(P^{(K)}\)</span> = <span class="math inline">\(A^k\)</span>이다.</li>
<li><code>Formula</code>
<ul>
<li><span class="math inline">\(S_{uv} = \sum \limits_{l=1}^\infty  \beta^l A_{uv}^{l}\)</span> (<span class="math inline">\(l\)</span> : Path의 길이, <span class="math inline">\(\beta\)</span>: Discount Factor(<span class="math inline">\(0&lt;\beta&lt;1\)</span>)</li>
<li><span class="math inline">\(S_{uv} = \sum \limits_{l=1}^\infty \beta^lA^i=(I-\beta A)^{-1}-I\)</span> (Closed-Form)</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="link-level-feature-summary" class="level3">
<h3 class="anchored" data-anchor-id="link-level-feature-summary">💡Link-Level Feature Summary</h3>
<pre><code>Link Level Feature는 3가지 분류로 나눌수 있다

1. Distance-Based :두 Node간 최단경로의 거리
2. Local Neigborhood Overlap : 두 Node가 공유하는 이웃의 수
3. Global Neighborhood Overlap : 두 Node를 잇는 모든 길이의 경로 가중합</code></pre>
<hr>
</section>
</section>
<section id="traditional-feature-based-method-graph" class="level2">
<h2 class="anchored" data-anchor-id="traditional-feature-based-method-graph">⛓&nbsp;Traditional Feature-Based Method : Graph</h2>
<hr>
<blockquote class="blockquote">
<p><strong>Goal : 전체 Graph 구조를 특정할 수 있는 Feature를 만드는 것</strong></p>
<ul>
<li>아이디어 : Graph로 Feature를 직접 만드는 대신 Kernel을 만들자.</li>
<li>Kernel <span class="math inline">\(K(G,G') \in \R\)</span> 은 두 Graph<span class="math inline">\((G)\)</span> 사이의 유사도를 측정한다.</li>
<li>Kernel Matrix는 항상 양의 고유값을 갖고 대칭행렬 이어야한다.</li>
<li>Feature Representaiton <span class="math inline">\(\phi(.)\)</span>이 존재한다.</li>
<li>이 Kernel을 SVM등에 붙여서 사용한다.</li>
</ul>
</blockquote>
<hr>
<section id="kernel-method" class="level3">
<h3 class="anchored" data-anchor-id="kernel-method">💡 Kernel Method</h3>
<ul>
<li><strong>Goal :</strong> Graph Feature Vector <span class="math inline">\(\phi(G)\)</span>를 설계한다</li>
<li><strong>Idea :</strong> Graph에 대해 Bow를 만든다.
<ul>
<li><p><em>Bow</em> : NLP에서 모든 단어가 몇 번 나타나는지 세는 방법</p></li>
<li><p><em>Naive Solution</em> : Node를 Word로 사용한다. 그러나 너무 Naive해서 써먹기 어렵다.</p>
<p><img src="https://i.imgur.com/c7WNp0e.png" class="img-fluid"></p></li>
<li><p><em>Node Degrees</em> : Node Degree를 Word로 사용한다.</p>
<p><img src="https://i.imgur.com/nLC4jnv.png" class="img-fluid"></p></li>
<li><p>이런식의 Bag-of-something 방식이 Graphlet Kernel과 WL Kernel에서도 사용된다.</p></li>
</ul></li>
</ul>
<hr>
</section>
<section id="grahplet-features" class="level3">
<h3 class="anchored" data-anchor-id="grahplet-features">💡 Grahplet Features</h3>
<ul>
<li><p><strong>Idea</strong> : Graph에 존재하는 서로 다른 Graphlet의 숫자를 세자</p></li>
<li><p><strong>Note :</strong> 이때의 Graphlet은 Node-Level과 조금 다른 정의를 갖고있다.</p>
<ul>
<li>Isolated Node로 Graphlet의 일부로 허용한다.</li>
<li>Root Node가 없다.</li>
</ul>
<p><img src="https://i.imgur.com/RCZYqWd.png" class="img-fluid"></p></li>
<li><p>Graph <span class="math inline">\(G\)</span>와 Graphlet list <span class="math inline">\(g_k = (g_1,g_2 ...g_{nk})\)</span>가 주어졌을 때 Graphlet Count Vector <span class="math inline">\(f_G \in \R^{nk}\)</span> 는 Graph에서 나타나는 각 Graphlet의 인스턴스 수로 정의된다.</p>
<ul>
<li><p><span class="math inline">\((f_G)_i = \#(g_i \in G)\)</span> | (for <span class="math inline">\(i = 1,2,...n_k)\)</span></p>
<p><img src="https://i.imgur.com/15aKkBh.png" class="img-fluid"></p></li>
</ul></li>
</ul>
</section>
<section id="graphlet-kernel" class="level3">
<h3 class="anchored" data-anchor-id="graphlet-kernel">💡 Graphlet Kernel</h3>
<ul>
<li>2개의 Graph <span class="math inline">\(G\)</span> 와 <span class="math inline">\(G'\)</span>가 주어지면, Graphlet Kernel은 <span class="math inline">\(K(G,G') = {f_G}^Tf_{G'}\)</span>로 표현될 수 있다(내적)</li>
<li><code>Problem</code> : <span class="math inline">\(G\)</span> 와 <span class="math inline">\(G'\)</span>가 크기(Scale)이 다르면 값이 크게 왜곡된다.</li>
<li><code>Solution</code>: <span class="math inline">\(f_G\)</span> 대신 Sum으로 나눠준 <span class="math inline">\(h_G\)</span>를 사용한다. <span class="math inline">\(h_G = {f_G \over Sum(f_G)}\)</span></li>
<li><code>Limitation</code> : Graphlet을 세는 연산이 매우 Expensive하다 !
<ul>
<li><span class="math inline">\(n\)</span> 크기의 Graph의 <span class="math inline">\(k\)</span> 크기의 Graphlet를 세려면 <span class="math inline">\(n^k\)</span>번 연산해야 한다.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="weisfeiler-lehmanwl-kernel" class="level3">
<h3 class="anchored" data-anchor-id="weisfeiler-lehmanwl-kernel">💡 Weisfeiler-Lehman(WL) Kernel</h3>
<ul>
<li><strong>Goal :</strong> 효율적인 Graph Feature Descriptor를 만드는 것
<ul>
<li>WL-Kernel은 강력하고 효율적이어서 인기가 많다.</li>
</ul></li>
<li><strong>Idea :</strong> Node Degree를 이용해 반복적으로 Node Vocap을 풍부하게 만들어 나가는 것
<ul>
<li>One-Hop Neighborhood인 Node Degree 방식을 일반화 한 버전이다.</li>
<li><strong><em>Color Refinement</em></strong> 알고리즘을 통해 이루어진다.</li>
</ul></li>
<li><strong>각 Step에서의 Time-Complexity가 Edge에 따라 Linear하게 증가한다.</strong></li>
</ul>
</section>
<section id="color-refinement" class="level3">
<h3 class="anchored" data-anchor-id="color-refinement">💡 Color Refinement</h3>
<ul>
<li><p><code>Given</code> : Graph <span class="math inline">\(G\)</span>와 그것들의 Set of Nodes <span class="math inline">\(V\)</span></p>
<ol type="1">
<li>Initial Color <span class="math inline">\(c^{(0)}(v)\)</span>를 각 노드 <span class="math inline">\(v\)</span>에 할당한다</li>
<li>Iteratively하게 Node의 Color를 정제해 나간다. <span class="math inline">\(c^{(k+1)}(v) = HASH(\{c^{(k)}(v), \{c^{(k)}(u) \}_{u\in N(v)})\)</span>
<ul>
<li>HASH는 다른 입력을 다른 Color로 매핑하는 연산이다.</li>
</ul></li>
<li><span class="math inline">\(K\)</span> Step 동안의 정제가 끝나면 <span class="math inline">\(c^{(K)}(v)\)</span> 값을 Summary한다.</li>
</ol>
<hr>
<ul>
<li><p>비슷하지만 조금 다른 Graph 두개 (<span class="math inline">\(G_1, G_2\)</span>)가 주어졌을때 Color Refienment 예시이다</p>
<ol type="1">
<li><p>동일한 Initial Color를 모든 Node에 할당한다.</p>
<p><img src="https://i.imgur.com/MbNlENL.png" class="img-fluid"></p></li>
<li><p>이웃하는 색상에 대해 Aggregate한다.</p>
<p><img src="https://i.imgur.com/qsIdHIv.png" class="img-fluid"></p></li>
<li><p>Aggregate된 Color를 HASH한다.</p>
<p><img src="https://i.imgur.com/ARtbUYJ.png" class="img-fluid"></p></li>
<li><p>이웃하는 색상에 대해 Aggregate한다.</p>
<p><img src="https://i.imgur.com/54MxJxX.png" class="img-fluid"></p></li>
<li><p>Aggregate된 Color를 HASH한다.</p>
<p><img src="https://i.imgur.com/jzDMsuL.png" class="img-fluid"></p></li>
<li><p>Color Refinement가 끝나면 WL Kernel이 각 Color가 등장했던 횟수를 세서 Summary한다.</p>
<p><img src="https://i.imgur.com/l2oEW8J.png" class="img-fluid"></p></li>
<li><p>Color Count Vector를 내적해 WL Kernel의 결과값을 구한다.</p>
<p><img src="https://i.imgur.com/XXN2ldt.png" class="img-fluid"></p></li>
</ol></li>
</ul></li>
</ul>
<hr>
</section>
<section id="graph-level-feature-summary" class="level3">
<h3 class="anchored" data-anchor-id="graph-level-feature-summary">💡 <strong><em>Graph-Level Feature Summary</em></strong></h3>
<pre><code>Graph Level Feature는 Kernel을 이용한다.

1. Graphlet Kernel :Bag-of-Graphlets, Computationally Expensive
2. WL- Kernel :
    - Color-Refinement 알고리즘을 이용해 반복적으로 피팅
    - Bag-of-Colors
    - Computationally Efficient !
    - Closely related to Graph Neural Networks</code></pre>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>